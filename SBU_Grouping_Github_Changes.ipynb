{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Input and output file names\n",
    "input_file = \"cleaned_encoded_decoded_col.csv\"\n",
    "output_file = \"top_30_percent_applications.csv\"\n",
    "\n",
    "# Step 1: Load the input CSV file\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Preview the dataset to ensure it has required columns like 'SBU' and 'Application'\n",
    "print(data.head())\n",
    "\n",
    "# Step 2: Group by SBU and calculate application frequencies\n",
    "grouped = data.groupby(['SBU', 'ApplicationName']).size().reset_index(name='Frequency')\n",
    "\n",
    "# Step 3: Identify the top 30% applications in each SBU\n",
    "top_30_percent_apps = []\n",
    "\n",
    "for sbu, group in grouped.groupby('SBU'):\n",
    "    # Sort applications by frequency\n",
    "    sorted_group = group.sort_values(by='Frequency', ascending=False)\n",
    "    # Calculate top 30% threshold\n",
    "    top_30_threshold = math.ceil(len(sorted_group) * 0.3)\n",
    "    # Select top 30% applications\n",
    "    top_apps = sorted_group.head(top_30_threshold)\n",
    "    top_30_percent_apps.append(top_apps)\n",
    "\n",
    "# Combine all top applications into a single DataFrame\n",
    "top_30_percent_apps_df = pd.concat(top_30_percent_apps)\n",
    "\n",
    "# Step 4: Save the results to a new CSV file\n",
    "top_30_percent_apps_df.to_csv(output_file, index=False)\n",
    "print(f\"Top 30% applications saved to {output_file}\")\n",
    "\n",
    "# Step 5: Visualize the data\n",
    "for sbu, group in top_30_percent_apps_df.groupby('SBU'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(group['ApplicationName'], group['Frequency'], color='skyblue')\n",
    "    plt.title(f\"Top 30% Applications in {sbu}\")\n",
    "    plt.xlabel(\"ApplicationName\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c499c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import xlsxwriter\n",
    "\n",
    "# Input and output file names\n",
    "input_file = \"cleaned_encoded_decoded_col.csv\"\n",
    "output_file = \"top_30_percent_applications_chart.xlsx\"\n",
    "\n",
    "# Step 1: Load the input CSV file\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Preview the dataset to ensure it has required columns like 'SBU' and 'ApplicationName'\n",
    "print(data.head())\n",
    "\n",
    "# Step 2: Group by SBU and calculate application frequencies\n",
    "grouped = data.groupby(['SBU', 'ApplicationName']).size().reset_index(name='Frequency')\n",
    "\n",
    "# Step 3: Identify the top 30% applications in each SBU\n",
    "top_30_percent_apps = []\n",
    "\n",
    "for sbu, group in grouped.groupby('SBU'):\n",
    "    # Sort applications by frequency\n",
    "    sorted_group = group.sort_values(by='Frequency', ascending=False)\n",
    "    # Calculate top 30% threshold\n",
    "    top_30_threshold = math.ceil(len(sorted_group) * 0.3)\n",
    "    # Select top 30% applications\n",
    "    top_apps = sorted_group.head(top_30_threshold)\n",
    "    top_30_percent_apps.append((sbu, top_apps))\n",
    "\n",
    "# Create an Excel writer object using xlsxwriter\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    # Access the workbook and add sheets\n",
    "    workbook = writer.book\n",
    "\n",
    "    # Step 4: Write each SBU's data to a separate sheet with a chart\n",
    "    for sbu, group in top_30_percent_apps:\n",
    "        # Write data to sheet\n",
    "        group.to_excel(writer, sheet_name=sbu, index=False, startrow=0, startcol=0)\n",
    "\n",
    "        # Add chart for visualization\n",
    "        worksheet = writer.sheets[sbu]\n",
    "        chart = workbook.add_chart({'type': 'column'})\n",
    "\n",
    "        # Configure the chart\n",
    "        chart.add_series({\n",
    "            'categories': [sbu, 1, 1, len(group), 1],  # ApplicationName column\n",
    "            'values': [sbu, 1, 2, len(group), 2],       # Frequency column\n",
    "            'name': f\"Top 30% Applications in {sbu}\",\n",
    "        })\n",
    "\n",
    "        # Add chart title and labels\n",
    "        chart.set_title({'name': f\"Top 30% Applications in {sbu}\"})\n",
    "        chart.set_x_axis({'name': 'ApplicationName'})\n",
    "        chart.set_y_axis({'name': 'Frequency'})\n",
    "\n",
    "        # Insert chart to the right of the data\n",
    "        worksheet.insert_chart('E2', chart)\n",
    "\n",
    "# Save the workbook\n",
    "print(f\"Excel file with top 30% applications and charts saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c023a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input and output file names\n",
    "input_file = \"top_30_percent_applications_chart.csv\"\n",
    "output_file = \"output_file_cleaned.csv\"\n",
    "\n",
    "# List of names (or values) to remove\n",
    "names_to_remove = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Step 1: Read the input CSV file\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"Preview of input data:\")\n",
    "print(data.head())\n",
    "\n",
    "# Step 2: Remove rows where a column matches any value in names_to_remove\n",
    "# Assuming we want to filter out rows in a specific column, e.g., 'Name'\n",
    "# Replace 'Name' with the column you want to filter\n",
    "if 'Name' in data.columns:\n",
    "    cleaned_data = data[~data['Name'].isin(names_to_remove)]\n",
    "else:\n",
    "    print(\"'Name' column not found in the dataset. Specify the correct column.\")\n",
    "    cleaned_data = data  # No filtering applied\n",
    "\n",
    "# Preview the cleaned dataset\n",
    "print(\"Preview of cleaned data:\")\n",
    "print(cleaned_data.head())\n",
    "\n",
    "# Step 3: Save the cleaned dataset back to CSV\n",
    "cleaned_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
